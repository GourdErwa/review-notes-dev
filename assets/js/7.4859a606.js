(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{221:function(r,a,e){r.exports=e.p+"assets/img/任务提交流程.9ab08a3b.png"},313:function(r,a,e){"use strict";e.r(a);var t=e(0),n=Object(t.a)({},(function(){var r=this,a=r.$createElement,t=r._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":r.$parent.slotKey}},[t("blockquote",[t("p",[r._v("专栏原创出处："),t("a",{attrs:{href:"https://github.com/GourdErwa/review-notes/tree/master/framework/spark-basis",target:"_blank",rel:"noopener noreferrer"}},[r._v("github-源笔记文件 "),t("OutboundLink")],1),r._v(" ，"),t("a",{attrs:{href:"https://github.com/GourdErwa/spark-advanced",target:"_blank",rel:"noopener noreferrer"}},[r._v("github-源码 "),t("OutboundLink")],1),r._v("，欢迎 Star，转载请附上原文出处链接和本声明。")])]),r._v(" "),t("p"),t("div",{staticClass:"table-of-contents"},[t("ul",[t("li",[t("a",{attrs:{href:"#一-部署模式"}},[r._v("一.部署模式")]),t("ul",[t("li",[t("a",{attrs:{href:"#_1-本地部署模式"}},[r._v("1.本地部署模式")])]),t("li",[t("a",{attrs:{href:"#_2-standalone-部署模式"}},[r._v("2.Standalone 部署模式")])]),t("li",[t("a",{attrs:{href:"#_3-on-yarn-部署模式"}},[r._v("3.On-Yarn 部署模式")])])])]),t("li",[t("a",{attrs:{href:"#二-任务提交流程"}},[r._v("二. 任务提交流程")]),t("ul",[t("li",[t("a",{attrs:{href:"#_1-standalone-模式"}},[r._v("1.Standalone 模式")])]),t("li",[t("a",{attrs:{href:"#_2-on-yarn-模式"}},[r._v("2.On-Yarn 模式")])]),t("li",[t("a",{attrs:{href:"#_3-yarn-client-和-yarn-cluster-的区别"}},[r._v("3.Yarn-Client 和 Yarn-Cluster 的区别")])])])])])]),t("p"),r._v(" "),t("h2",{attrs:{id:"一-部署模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一-部署模式"}},[r._v("#")]),r._v(" 一.部署模式")]),r._v(" "),t("h3",{attrs:{id:"_1-本地部署模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-本地部署模式"}},[r._v("#")]),r._v(" 1.本地部署模式")]),r._v(" "),t("p",[r._v("local 部署模式只有 Driver，没有 Master 和 Worker，执行任务的 Executor 与 Driver 在同一个 JVM 进程内，此类模式主要用于代码调试和跟踪，不具备高可用性、可扩展性，所以不适用于生产环境。")]),r._v(" "),t("p",[t("strong",[r._v("设置 master 的几种方式：")])]),r._v(" "),t("ul",[t("li",[t("p",[r._v("local 只运行一个 Worker 线程。")])]),r._v(" "),t("li",[t("p",[r._v("local[N] 运行 N 个 Worker 线程。")])]),r._v(" "),t("li",[t("p",[r._v("local[*] 运行 CPU 最大核数相同数量的 Worker 线程。")])]),r._v(" "),t("li",[t("p",[r._v("local[N,M] 运行 N 个 Worker 线程，失败的任务进行 M-1 次重试。")])]),r._v(" "),t("li",[t("p",[r._v("local[*,M] 运行 CPU 最大核数相同数量的 Worker 线程，失败的任务进行 M-1 次重试。")])])]),r._v(" "),t("h3",{attrs:{id:"_2-standalone-部署模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-standalone-部署模式"}},[r._v("#")]),r._v(" 2.Standalone 部署模式")]),r._v(" "),t("p",[r._v("此模式具备高可用性并且支持分布式部署，所以可用于实际的生产环境。")]),r._v(" "),t("ul",[t("li",[t("p",[r._v("使用此模式首先要有一个 Spark 集群环境，也就是要启动一个 Master 和 若干个 Worker 节点。可以通过 SPARK_HOME/sbin/ 目录下的启动脚本，启动相应的组件。")])]),r._v(" "),t("li",[t("p",[r._v("CoarseGrainedExecutorBackend 是执行任务的进程名称，当你提交了任务之后，可以看到该进程的运行，它其实就是 Executor。")])]),r._v(" "),t("li",[t("p",[r._v("通过 --master spark://HOST:PORT 来使用 Standalone 模式提交任务。")])]),r._v(" "),t("li",[t("p",[r._v("使用 spark-shell 提交任务的时候，Driver 位于 Master 端。")])]),r._v(" "),t("li",[t("p",[r._v("使用 spark-submit 或者在 Eclips、Idea 开发平台该上提交任务的时候，Driver 位于 Client 端。")])])]),r._v(" "),t("h3",{attrs:{id:"_3-on-yarn-部署模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-on-yarn-部署模式"}},[r._v("#")]),r._v(" 3.On-Yarn 部署模式")]),r._v(" "),t("p",[r._v("将 Spark 任务的整体运作交给 Yarn 集群管理，不需要启动 Master 和 Worker，所有的资源调度和执行任务容器的创建都由 Yarn 来完成。")]),r._v(" "),t("ul",[t("li",[t("p",[r._v("通过 --master yarn 来指定 Spark On Yarn 的部署模式。")])]),r._v(" "),t("li",[t("p",[r._v("该模式又有两种子模式，通过 --deploy-mode cluster 或者 --deploy-mode client 来指定，cluster 和 client 两种模式唯一的区别就是 Driver 端运行的位置不一样。")])])]),r._v(" "),t("h2",{attrs:{id:"二-任务提交流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#二-任务提交流程"}},[r._v("#")]),r._v(" 二. 任务提交流程")]),r._v(" "),t("div",{attrs:{align:"center"}},[t("img",{attrs:{src:e(221)}}),r._v(" "),t("p",[r._v(" 任务提交流程 ")])]),r._v(" "),t("h3",{attrs:{id:"_1-standalone-模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-standalone-模式"}},[r._v("#")]),r._v(" 1.Standalone 模式")]),r._v(" "),t("ul",[t("li",[t("p",[r._v("用户提交任务后通过 SparkSubmit 类的 main 方法匹配到 SUBMIT 模式，然后调用 submit 方法，通过反射获取到主类对象并执行主类对象的 main 方法。")])]),r._v(" "),t("li",[t("p",[r._v("然后构建 SparkConf 和 SparkContext，其中 SparkContext 中又初始化了 SparkEnv、DAGScheduler、TaskScheduler 这三个对象。")])]),r._v(" "),t("li",[t("p",[r._v("任务的相关信息被封装到了 ApplicationDescription 之后，由 StandaloneAppClient 携带发送给 Master。")])]),r._v(" "),t("li",[t("p",[r._v("Master 接收到任务信息后将其放入内存，并在 waitingApps 队列中也保存一份，当开始执行该任务时，调用 schedule 方法进行资源调度。")])]),r._v(" "),t("li",[t("p",[r._v("将计算好的调度资源封装到 LaunchExecutor 中发送给 Worker，Worker 接收到调度信息后，将其封装成一个 ExecutorRunner 对象并调用 start 方法启动 CoarseGrainedExecutorBackend 进程。")])]),r._v(" "),t("li",[t("p",[r._v("Executor 启动后向 Driver 反向注册，注册成功后会创建一个线程池 ThreadPool 来执行任务。")])]),r._v(" "),t("li",[t("p",[r._v("Executor 注册完成后，Driver 开始执行我们提交的任务，当执行了 action 算子之后，这时就触发了一个 job，然后调用 DAGScheduler 进行 Stage 划分。")])]),r._v(" "),t("li",[t("p",[r._v("划分好的 Stage 会按照分区生成 Task，这些 Task 会被封装成 TaskSet 提交给 TaskScheduler。")])]),r._v(" "),t("li",[t("p",[r._v("TaskScheduler 拿到这些任务集合后，会用一个序列化器，将这些 TaskSet 进行序列化，然后封装到 LaunchExecutor 中发送给 Executor。")])]),r._v(" "),t("li",[t("p",[r._v("Executor 接收到这些任务后，再将它们封装成 TaskRunner，然后丢到线程池中执行。")])]),r._v(" "),t("li",[t("p",[r._v("TaskRunner 会被反序列化成 TaskSet，然后执行每个 Task 中的任务，也就是对 RDD 的每个分区上执行对应的算子。")])]),r._v(" "),t("li",[t("p",[r._v("Driver 负责监控任务的运行情况，重试失败的任务。任务运行完成之后 Driver 会向 Master 申请注销，然后 Master 释放相关资源。")])])]),r._v(" "),t("h3",{attrs:{id:"_2-on-yarn-模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-on-yarn-模式"}},[r._v("#")]),r._v(" 2.On-Yarn 模式")]),r._v(" "),t("p",[r._v("与 Standalone 模式运行的整体流程大体一致，只是所有的功能都统一交给了 Yarn 来管理。")]),r._v(" "),t("ul",[t("li",[t("p",[r._v("On-Yarn 模式多了一个组件就是 Application Master(简称 AM)，AM 负责资源的申请以及任务运行情况的监控。客户端提交了任务后，ResourceManager(简称 RM) 会首先创建一个容器启动 AM，AM 获取到 Driver 需要的资源信息之后向 RM 申请资源，RM 找到合适的 NodeManager(简称 NM) 后在上面创建 Container 容器，并将这些容器信息返回给 AM，AM 与这些容器对应的 NM 建立通信，并在容器里启动 Executor。")])]),r._v(" "),t("li",[t("p",[r._v("RM 主要负责监控集群中所有组件的运行情况以及向 AM 分配资源、创建 Container 容器。")])]),r._v(" "),t("li",[t("p",[r._v("RM 和 AM 整体相当于 Master，NM 相当于 Worker，RM 会在 NM 上创建容器 Container 来启动相关的组件。")])])]),r._v(" "),t("h3",{attrs:{id:"_3-yarn-client-和-yarn-cluster-的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-yarn-client-和-yarn-cluster-的区别"}},[r._v("#")]),r._v(" 3.Yarn-Client 和 Yarn-Cluster 的区别")]),r._v(" "),t("ul",[t("li",[t("p",[r._v("Yarn-Client 和 Yarn-Cluster 模式的唯一区别就是 Driver 启动的位置不同，Client 模式下 Driver 启动在用户提交任务的客户端上，用户可以看到 Driver 输出的日志，程序如果中断，整体任务就断掉了；Cluster 模式下，Driver 运行在 AM 中，客户端看不到 Driver 输出的日志，并且客户端提交完任务之后可以强行中断掉，并不会影响任务的正常运行。")])]),r._v(" "),t("li",[t("p",[r._v("Yarn-Cluster 更适合用于生产环境，因为 Client 模式下，Driver 运行在客户端，当 Driver 和 Executor 之间有大量通信的时候，会造成网络 I/O 的压力，并且如果客户端提交了许多 Spark  任务的话，客户端启动的大量 Driver 程序对客户端的资源也会造成一定的压力。``")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);